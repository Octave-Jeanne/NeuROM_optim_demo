{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e820c28",
   "metadata": {},
   "source": [
    "# Magnetostatic (linear) topology optimisation pareto front\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0af16f",
   "metadata": {},
   "source": [
    "### Path setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f3632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_to_this_folder = os.getcwd() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df34525",
   "metadata": {},
   "source": [
    "### Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a10a4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"   # Prevent internal ngsolve imports from killing the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19447e9f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09616f3",
   "metadata": {},
   "source": [
    "Usual libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e79d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib\n",
    "from time import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195bf338",
   "metadata": {},
   "source": [
    "NeuROM-optim, our in-house library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8bfedaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurom_optim.Pre_processing.process_hardware import get_precision, get_device\n",
    "from neurom_optim.Pre_processing.process_gmsh import read_gmsh, get_nodes_and_elements_IDs\n",
    "from neurom_optim.FENN.VertexNN.FEENN_2D.FEENN import FEENN_2D\n",
    "from neurom_optim.FENN.VertexNN.FEENN_2D.Element import Tri_2D_lin\n",
    "from neurom_optim.FENN.VertexNN.FEENN_2D.Mapping import Mapping_2D_Affine\n",
    "from neurom_optim.FENN.ConstantNN.constantNN import ConstantNN\n",
    "from neurom_optim.FENN.L2NN.field_L2NN import Field_L2NN\n",
    "from neurom_optim.PropertiesNN.PropertiesNN import PropertiesNN\n",
    "from neurom_optim.Pre_processing.build_solver import build_solver\n",
    "from neurom_optim.PDE.Magnetostatic_Optim_2D_loss import Magnetostatic_Optim_2D_loss\n",
    "from neurom_optim.PDE.operators import curl\n",
    "from neurom_optim.MaterialNN.BinarySelection import BinarySelection\n",
    "from neurom_optim.Baselines.Poisson_2D.Uniform.baseline import baseline\n",
    "from neurom_optim.Post_processing.VTKExport.export_vtk import export_vtk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03636d8e",
   "metadata": {},
   "source": [
    "### ### Number precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "309570a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IntPrecision = torch.int32\n",
    "FloatPrecision = torch.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b060d6e7",
   "metadata": {},
   "source": [
    "### Hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967818f8",
   "metadata": {},
   "source": [
    "*Note that for cases of small meshes cpu outperforms gpu*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb02f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869be76e",
   "metadata": {},
   "source": [
    "# Problem description and problem-related variables definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3626476c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "        \\;&\\text{Find }&&\\overrightarrow{A}^*,\\rho^* =\\arg\\min_{\\overrightarrow{A}\\in H\\left(\\overrightarrow{\\text{rot}},\\Omega\\right), \\rho\\in L^2(\\Omega)}\\int_\\Omega \\frac{1}{2\\mu(x)}\\cdot\\overrightarrow{\\text{curl}}\\left(\\overrightarrow{A}\\right) \\cdot\\overrightarrow{\\text{curl}}\\left(\\overrightarrow{A}\\right)-\\overrightarrow{j}\\cdot\\overrightarrow{A}\\text{d}\\Omega\n",
    "        + \\lambda\\frac{\\int_\\Omega \\rho(x)\\text{d}\\Omega}{\\int_\\Omega\\text{d}\\Omega}\n",
    "        \\\\\\\\\n",
    "        &\\text{s.t}&&\\overrightarrow{A}(x^+)\\cdot \\overrightarrow{e}_z=A_0\\\\\n",
    "        &&&\\overrightarrow{A}(x^-)\\cdot \\overrightarrow{e}_z = -A_0\\\\\n",
    "        &&&\\overrightarrow{A}(x) = \\overrightarrow{0}&\\forall x\\in\\partial \\Omega\\\\\n",
    "        &&&\\mu(x) = \\mu_0&\\forall x\\in \\Omega \\backslash \\Omega^+\\bigcup\\Omega^-\\\\\n",
    "        &&&\\mu_0\\leq\\mu(x)\\leq\\mu_1&\\forall x\\in\\Omega^+\\bigcup\\Omega^-\\\\\n",
    "        &&&\\overrightarrow{j}(x) = \\overrightarrow{0}&\\forall x\\in \\Omega\\\\\n",
    "        \n",
    "    \\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964de452",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$\\mu$ can multiple values between $\\mu_0$ and $\\mu_1$ depending on the location in $\\Omega$.  \n",
    "For conveniency \n",
    "- we use $\\nu = \\frac{1}{\\mu}$\n",
    "- we enforce the switch between $\\nu_0$ and $\\nu_1$ through a soft choice field $\\rho:\\Omega\\to[0,1]$ such that\n",
    "$$\n",
    "\\nu(x) = (1-\\rho(x))\\nu_0 +\\rho(x)\\nu_1\n",
    "$$\n",
    "\n",
    "We enforce $\\rho:\\Omega\\to[0,1]$ through the auxiliary field $\\hat{\\rho}:\\Omega\\to\\mathbb{R}$ and the sigmoïd.\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\;&\\rho(x)=\\mathbb{I}\\left\\{x\\notin \\Omega^+\\bigcup\\Omega^-\\right\\}\\sigma\\left(\\hat{\\rho}(x)-\\frac{1}{2}\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "After the optimization, one can force $\\mu(x)\\in\\{\\mu_0,\\mu_1\\}$ by taking\n",
    "$$\n",
    "\\nu(x) = (1-p(x))\\nu_0 +p(x)\\nu_1\n",
    "$$\n",
    "\n",
    "Where $p$ is the hard choice field given by :\n",
    "$$\n",
    "p(x) = \\mathbb{I}\\left\\{\\rho(x)\\geq 0.5\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f292bf0",
   "metadata": {},
   "source": [
    "$\\Omega$ is defined through a .msh file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f76ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_msh = os.path.join(path_to_this_folder, \"Coil.msh\")\n",
    "# path_to_msh = os.path.join(path_to_this_folder, \"Coil_fine.msh\")\n",
    "# path_to_msh = os.path.join(path_to_this_folder, \"Coil_interm.msh\")\n",
    "path_to_msh = os.path.join(path_to_this_folder, \"Coil_TC.msh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d159c56",
   "metadata": {},
   "source": [
    "Define $\\nu_0$ and $\\nu_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f8abdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_0_value = 1\n",
    "nu_1_value = 2e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d158ca75",
   "metadata": {},
   "source": [
    "No source term because $\\overrightarrow{j} = \\overrightarrow{0}$ in $\\Omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491e5b4f",
   "metadata": {},
   "source": [
    "The problem is set in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d39c21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "interior_dim = 2\n",
    "boundary_dim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546afd4",
   "metadata": {},
   "source": [
    "$\\overrightarrow{A}$ is a vector field that can be represented as a scalar field carried by $\\overrightarrow{e}_z$. Hence only one component is necessary to identify $\\overrightarrow{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "904e032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 1\n",
    "\n",
    "dirichlet_exterior = {'entity_name'         : 'Exterior',\n",
    "                        'Value'              : 0}\n",
    "\n",
    "dirichlet_positive_source = {'entity_name'                       : 'Positive_source',\n",
    "                            'entity_dim'                         : 0,\n",
    "                            'Value'                              : 1 }\n",
    "\n",
    "dirichlet_negative_source = {'entity_name'                       : 'Negative_source',\n",
    "                            'entity_dim'                         : 0,\n",
    "                            'Value'                              : -1}\n",
    "\n",
    "dirichlet_config = [dirichlet_exterior, dirichlet_positive_source, dirichlet_negative_source]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e3f72",
   "metadata": {},
   "source": [
    "We use a linear interpolation for our FEM representation of $V$. Therefore $\\overrightarrow{\\text{curl}}(\\overrightarrow{A})$ is constant by element and the appropriate integration scheme is an order 1 gaussian quadrature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41550cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrature_order = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21dc074",
   "metadata": {},
   "source": [
    "# FENN solve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cb4a9e",
   "metadata": {},
   "source": [
    "Read the gmsh file and get the mesh related info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a987c23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GMSH file: 100%|██████████| 7984/7984 [00:00<00:00, 485464.24it/s]\n"
     ]
    }
   ],
   "source": [
    "gmsh_mesh = read_gmsh(path_to_msh = path_to_msh,\n",
    "                      IntPrecision = IntPrecision,\n",
    "                      FloatPrecision = FloatPrecision)\n",
    "\n",
    "Nodes = gmsh_mesh.nodes\n",
    "connectivity = gmsh_mesh.elements[str(interior_dim)]['connectivity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7c3ea1",
   "metadata": {},
   "source": [
    "## One specific FENN solve\n",
    "\n",
    "Note : We wrap everything into modulable functions so that its easier to do the pareto front in the next part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8064e5cc",
   "metadata": {},
   "source": [
    "Build a field candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "112ce2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_field_candidate():\n",
    "    global gmsh_mesh, Nodes, connectivity, dirichlet_config, interior_dim, boundary_dim, IntPrecision, FloatPrecision, n_components, quadrature_order, device\n",
    "\n",
    "    \n",
    "\n",
    "    # Build the field candidate. Here we use a linear interpolation scheme.\n",
    "    A = FEENN_2D(Nodes = Nodes,\n",
    "                connectivity=connectivity,\n",
    "                n_components=n_components,\n",
    "                element=Tri_2D_lin(IntPrecision=IntPrecision, FloatPrecision=FloatPrecision),\n",
    "                mapping = Mapping_2D_Affine(),\n",
    "                IntPrecision=IntPrecision,\n",
    "                FloatPrecision=FloatPrecision)\n",
    "\n",
    "    # Apply dirichlet\n",
    "    for dirichlet in dirichlet_config:\n",
    "\n",
    "        nodeIDs, _ = get_nodes_and_elements_IDs(gmsh_mesh=gmsh_mesh,\n",
    "                                                entity_dim = dirichlet.get('entity_dim', boundary_dim),\n",
    "                                                entity_name = dirichlet.get('entity_name', None),\n",
    "                                                entity_tag = dirichlet.get('entity_tag', None))\n",
    "        \n",
    "        \n",
    "        value = dirichlet['Value']*torch.ones_like(nodeIDs, dtype = FloatPrecision).unsqueeze(-1)\n",
    "\n",
    "        A.SetBCs(Fixed_nodal_coordinates_Ids = nodeIDs,\n",
    "                Fixed_nodal_values_Ids = nodeIDs,\n",
    "                Fixed_nodal_values_values = value)\n",
    "        \n",
    "\n",
    "    # Specify the integration scheme\n",
    "    A.SetQuad(quadrature_order = quadrature_order)\n",
    "    A.Freeze(freeze_grid=True, freeze_interpolation=False)\n",
    "\n",
    "    # Move the object to the chosen hardware\n",
    "    A.to(device)\n",
    "\n",
    "    # Specify that A should store its evolution so that we can export it to vtk\n",
    "    A.StoreResults()\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cad719",
   "metadata": {},
   "source": [
    "Define the material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b0de5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_material():\n",
    "    global gmsh_mesh, u_0_value, nu_1_value, IntPrecision, FloatPrecision, interior_dim, device\n",
    "    \n",
    "    connectivity = gmsh_mesh.elements[str(interior_dim)]['connectivity']\n",
    "\n",
    "    # Define the nu_0 property\n",
    "    nu_0 = ConstantNN(property_value=nu_0_value,\n",
    "                        IntPrecision = IntPrecision,\n",
    "                        FloatPrecision = FloatPrecision)\n",
    "\n",
    "    # nu_0 is not a field to be found\n",
    "    nu_0.setBCs(is_fixed=True)\n",
    "\n",
    "    # Define the nu_1 property\n",
    "    nu_1 = ConstantNN(property_value=nu_1_value,\n",
    "                        IntPrecision = IntPrecision,\n",
    "                        FloatPrecision = FloatPrecision)\n",
    "\n",
    "    # nu_1 is not a field to be found\n",
    "    nu_1.setBCs(is_fixed=True)\n",
    "\n",
    "\n",
    "    # Define the nu property using nu_0 and nu_1\n",
    "    # BinarySelection.forward(el_ids, NPoints, *args, **kwargs) -> (1-choice)*self.properties['property_1'](el_ids, NPoints, *args, **kwargs) + choice*self.properties['property_2'](el_ids, NPoints, *args, **kwargs)\n",
    "    nu = BinarySelection(property_1     = nu_0,\n",
    "                        property_2     = nu_1,\n",
    "                        NElem          = len(connectivity),\n",
    "                        IntPrecision   = IntPrecision,\n",
    "                        FloatPrecision = FloatPrecision)\n",
    "\n",
    "\n",
    "    # Note that we do not enforce anything in \"domain_no_coil\", i.e : nu is a field to be found in that part of the domain\n",
    "   \n",
    "\n",
    "    # Set the value of nu to nu_0 in \"coil_1\"\n",
    "    _, elemIDs = get_nodes_and_elements_IDs(gmsh_mesh=gmsh_mesh,\n",
    "                                                entity_dim=interior_dim,\n",
    "                                                entity_name = 'coil_1')\n",
    "\n",
    "    nu.setBCs(Fixed_Ids=elemIDs, specific_value=torch.zeros_like(elemIDs))\n",
    "\n",
    "    # Set the value of nu to nu_0 in \"coil_2\"\n",
    "    _, elemIDs = get_nodes_and_elements_IDs(gmsh_mesh=gmsh_mesh,\n",
    "                                                entity_dim=interior_dim,\n",
    "                                                entity_name = 'coil_2')\n",
    "\n",
    "    nu.setBCs(Fixed_Ids=elemIDs, specific_value=torch.zeros_like(elemIDs))\n",
    "\n",
    "    # The only problem-relevant material property is nu\n",
    "    Mat = PropertiesNN(dim = interior_dim,\n",
    "                    NElem = len(connectivity),\n",
    "                    IntPrecision = IntPrecision,\n",
    "                    FloatPrecision = FloatPrecision)\n",
    "\n",
    "    Mat.add_property(property_name = 'nu',\n",
    "                    property = nu)\n",
    "\n",
    "    # Move the object to the chosen hardware\n",
    "    Mat.to(device)\n",
    "\n",
    "    return Mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68192f9b",
   "metadata": {},
   "source": [
    "Define the objective function and how the fields of interest should be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b142fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_objective_function(run_index, lagrange_multiplier):\n",
    "    specific_run_name = f'optim_run_{run_index}_lagrange_multiplier_{lagrange_multiplier}'\n",
    "\n",
    "    path_to_main_vtk_folder = os.path.join(os.path.join(path_to_this_folder, 'Results'), 'VTK_exports')\n",
    "    os.makedirs(path_to_main_vtk_folder, exist_ok = True)\n",
    "\n",
    "    path_to_specific_vtk_folder = os.path.join(path_to_main_vtk_folder, specific_run_name)\n",
    "\n",
    "    vtk_export_config = {'path_to_folder'       : path_to_specific_vtk_folder,\n",
    "                    'cell_data'             : ['B', 'potential', 'j', 'field_term', 'source_term', 'nu', 'mapping_det', 'soft_choice', 'hard_choice'],\n",
    "                    'point_data'            : ['A'],\n",
    "                    'export_vtk'            : True}\n",
    "    \n",
    "\n",
    "    loss = Magnetostatic_Optim_2D_loss(IntPrecision=IntPrecision, \n",
    "                                        FloatPrecision=FloatPrecision,\n",
    "                                        vtk_export = vtk_export_config,\n",
    "                                        lagrange_multiplier = lagrange_multiplier)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b081fb15",
   "metadata": {},
   "source": [
    "Specify the solver and build it. Beware that even though the physics is convex, the overall objective is not. Nevertheless, LBFGS (quasi-Newton) behaves well in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce2e9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specify_solver(loss, A, Mat, lagrange_multiplier):\n",
    "    solver_config = {'optimizer'               :  'lbfgs',\n",
    "            'n_epochs'                :  5000,\n",
    "            'loss_decrease_c'         :   1e-13,\n",
    "            'freeze_grid'             :   True,\n",
    "            'freeze_interpolation'    :   False,\n",
    "            'freeze_Mat'              :   False,\n",
    "            'budget'                  : 0,\n",
    "            'lagrange_multiplier'     : 0,\n",
    "            'focus_multiplier'        : lagrange_multiplier}\n",
    "\n",
    "    solver = build_solver(solver_config = solver_config,\n",
    "                        loss = loss,\n",
    "                        model = A,\n",
    "                        Mat = Mat)\n",
    "    \n",
    "    return solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adfbcdc",
   "metadata": {},
   "source": [
    "Extract, plot, save and return some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a198bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_plot_save_and_return_some_metrics(run_index, lagrange_multiplier, solver):\n",
    "\n",
    "    # Get all metrics of interest\n",
    "    epochs, loss = solver.get_metric()\n",
    "    time_steps, _ = solver.get_metric(use_time = True)\n",
    "    _, physical_loss = solver.get_metric(name = 'potential')\n",
    "    _, constraint_loss = solver.get_metric(name = 'volume_term')\n",
    "\n",
    "    \n",
    "    # Define the path to the main plot save folder\n",
    "    save_folder = os.path.join(os.path.join(path_to_this_folder, 'Results'), 'Plots')\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    # Define the path to the run-related plots\n",
    "    specific_save_folder = os.path.join(save_folder, f\"run_{run_index}_lagrange_multiplier_{lagrange_multiplier}\")\n",
    "    os.makedirs(specific_save_folder, exist_ok=True)\n",
    "\n",
    "    # Plot and save the loss evolution\n",
    "    save_name = f\"loss.png\"\n",
    "    save_path = os.path.join(specific_save_folder, save_name)\n",
    "    plt.clf()\n",
    "    plt.plot(epochs, loss)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'run {run_index}\\t,\\t'+r'$\\lambda$ = '+f'{lagrange_multiplier}')\n",
    "    plt.grid(True, which='both')\n",
    "    plt.savefig(save_path)\n",
    "    \n",
    "    # Plot and save the physics-related term evolution\n",
    "    save_name = f\"physics_loss.png\"\n",
    "    save_path = os.path.join(specific_save_folder, save_name)\n",
    "    plt.clf()\n",
    "    plt.plot(epochs, physical_loss)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Magnetic energy')\n",
    "    plt.title(f'run {run_index}\\t,\\t'+r'$\\lambda$ = '+f'{lagrange_multiplier}')\n",
    "    plt.grid(True, which='both')\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "    # Plot and save the volume-related term evolution\n",
    "    save_name = f\"constraint_loss.png\"\n",
    "    save_path = os.path.join(specific_save_folder, save_name)\n",
    "    plt.clf()\n",
    "    plt.plot(epochs, constraint_loss)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Volume constraint')\n",
    "    plt.title(f'run {run_index}\\t,\\t'+r'$\\lambda$ = '+f'{lagrange_multiplier}')\n",
    "    plt.grid(True, which='both')\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "    # Return the last metrics values from multiple-run related plots\n",
    "    return time_steps[-1], physical_loss[-1], constraint_loss[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38cf79f",
   "metadata": {},
   "source": [
    "Wrap everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc16fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim_run(run_index, lagrange_multiplier):\n",
    "\n",
    "    # Build every object of interest\n",
    "    A = build_field_candidate()\n",
    "    Mat = build_material()\n",
    "    loss = build_objective_function(run_index, lagrange_multiplier)\n",
    "    solver = specify_solver(loss, A, Mat, lagrange_multiplier)\n",
    "\n",
    "    # Solve\n",
    "    solver.solve()\n",
    "\n",
    "    # Metric processing\n",
    "    duration, physical_loss, constraint_loss = extract_plot_save_and_return_some_metrics(run_index, lagrange_multiplier, solver)\n",
    "\n",
    "    # Return some run-based metrics for the overall pareto front\n",
    "    return duration, physical_loss, constraint_loss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9d61a",
   "metadata": {},
   "source": [
    "## FENN solve for multiple lagrange multipliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd98865",
   "metadata": {},
   "source": [
    "Set the considered multiplier values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63d2bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # What was done for the paper\n",
    "# lagrange_multipliers_start = -6\n",
    "# lagrange_multipliers_stop = 3\n",
    "# lagrange_multipliers_number = 100\n",
    "# lagrange_multipliers = torch.logspace(start = lagrange_multipliers_start, end = lagrange_multipliers_stop, steps = lagrange_multipliers_number).data.numpy()\n",
    "\n",
    "# Improved choice\n",
    "\n",
    "low_lagrange_multipliers = torch.logspace(start = -5, end = -1, steps = 5).data.numpy()\n",
    "\n",
    "middle_lagrange_multipliers = torch.logspace(start = -1, end = 2, steps = 15).data.numpy()\n",
    "\n",
    "high_lagrange_multipliers = torch.logspace(start = 2, end = 3, steps = 5).data.numpy()\n",
    "\n",
    "lagrange_multipliers = np.concatenate([low_lagrange_multipliers, middle_lagrange_multipliers, high_lagrange_multipliers])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e2e76",
   "metadata": {},
   "source": [
    "Do all runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c142ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandre/Documents/Code/NeuROM_optim/neurom_optim/FENN/VertexNN/FEENN_2D/FEENN.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('connectivity', torch.tensor(connectivity, dtype = self.ref_int.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###############################################################################\n",
      "Run\t:\t1/25\n",
      "lagrange_multiplier\t:\t9.999999747378752e-06\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving (worse case scenario):  21%|██        | 1043/5000 [02:14<04:37, 14.28it/s, time=134]/Users/alexandre/Documents/Code/NeuROM_optim/neurom_optim/FENN/VertexNN/FEENN_2D/FEENN.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('connectivity', torch.tensor(connectivity, dtype = self.ref_int.dtype))\n",
      "Solving (worse case scenario):  21%|██        | 1043/5000 [02:14<08:30,  7.76it/s, time=134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###############################################################################\n",
      "Run\t:\t2/25\n",
      "lagrange_multiplier\t:\t9.999999747378752e-05\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving (worse case scenario):  16%|█▌        | 788/5000 [01:43<09:14,  7.59it/s, time=104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###############################################################################\n",
      "Run\t:\t3/25\n",
      "lagrange_multiplier\t:\t0.0010000000474974513\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving (worse case scenario):   5%|▍         | 237/5000 [00:33<11:30,  6.90it/s, time=33.1]"
     ]
    }
   ],
   "source": [
    "all_durations = []\n",
    "all_physical_loss = []\n",
    "all_constraint_loss = []\n",
    "\n",
    "# Solve the optimization problem for every multiplier values and stores the metrics values at convergence\n",
    "for run_index, lagrange_multiplier in enumerate(lagrange_multipliers):\n",
    "    print(f'\\n\\n###############################################################################\\nRun\\t:\\t{run_index+1}/{len(lagrange_multipliers)}\\nlagrange_multiplier\\t:\\t{lagrange_multiplier}\\n\\n')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    duration, physical_loss, constraint_loss = optim_run(run_index, lagrange_multiplier)\n",
    "\n",
    "    all_durations.append(duration)\n",
    "    all_physical_loss.append(physical_loss)\n",
    "    all_constraint_loss.append(constraint_loss)\n",
    "\n",
    "# Define the path to the main plot save folder\n",
    "save_folder = os.path.join(os.path.join(path_to_this_folder, 'Results'), 'Plots')\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Define the path to the global plots save folder\n",
    "specific_save_folder = os.path.join(save_folder, f\"Global_plots\")\n",
    "os.makedirs(specific_save_folder, exist_ok=True)\n",
    "\n",
    "# Plot and save the physics-related term at convergence vs the lagrange multiplier values\n",
    "save_name = f'Physics_vs_lagrange_multipliers.png'\n",
    "save_path = os.path.join(specific_save_folder, save_name)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(lagrange_multipliers, all_physical_loss, '.')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Magnetic energy')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, which='both')\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# Plot and save the volume-related term at convergence vs the lagrange multiplier values\n",
    "save_name = f'Volume_vs_lagrange_multipliers.png'\n",
    "save_path = os.path.join(specific_save_folder, save_name)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(lagrange_multipliers, all_constraint_loss, '.')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Volume penalty')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, which='both')\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# Plot and save the physics-related term at convergence vs the volume-related term at convergence (i.e : pareto front of the optimization problem)\n",
    "save_name = f'Pareto.png'\n",
    "save_path = os.path.join(specific_save_folder, save_name)\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(all_constraint_loss, all_physical_loss, c=lagrange_multipliers, cmap='viridis', norm=LogNorm())\n",
    "plt.colorbar(label=\"Lagrange multiplier\")  # Optional color legend to add infos on the lagrange multiplier dependencies\n",
    "plt.xlabel(\"Volume Penalty\")\n",
    "plt.ylabel(\"Magnetic Energy\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, which='both')\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# Define the path to the metrics save folder (to allow for some additionnal post-processing)\n",
    "save_folder = os.path.join(os.path.join(path_to_this_folder, 'Results'), 'Run_wise_metrics')\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Save every global metrics\n",
    "all_durations       =   np.array(all_durations)\n",
    "all_physical_loss   =   np.array(all_physical_loss)\n",
    "all_constraint_loss =   np.array(all_constraint_loss)\n",
    "\n",
    "np.save(os.path.join(save_folder, f'all_durations.npy'), all_durations)\n",
    "np.save(os.path.join(save_folder, f'all_physical_loss.npy'), all_physical_loss)\n",
    "np.save(os.path.join(save_folder, f'all_constraint_loss.npy'), all_constraint_loss)\n",
    "np.save(os.path.join(save_folder, f'lagrange_multipliers.npy'), lagrange_multipliers)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurom-optim-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
